{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Customer Attrition Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * The client would like to better understand the patterns in the employee base so that the client can learn the variables of an employee least likely to attrition. \n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/EmployeeAttrition.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code and seaborn plots that answer business requirement 1 and can be used for the Streamlit App\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Need to change working directory from the current jupyter_notebooks folder to the parent folder in order to access the whole project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/EmployeeAttrition.csv\").drop(['EmployeeCount', 'EmployeeNumber'], axis=1))\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We wish to become familiar with the dataset, check variable types and their distribution, check for any missing data, and to understand what these variables mean in the business context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip show pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "outputs": [
        {
          "ename": "PydanticImportError",
          "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.0.2/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.0.2/u/import-error",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mydata_profiling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m pandas_report \u001b[38;5;241m=\u001b[39m ProfileReport(df\u001b[38;5;241m=\u001b[39mdf, minimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m pandas_report\u001b[38;5;241m.\u001b[39mto_notebook_iframe\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/ydata_profiling/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Main module of ydata-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompare_reports\u001b[39;00m \u001b[39mimport\u001b[39;00m compare\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontroller\u001b[39;00m \u001b[39mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/ydata_profiling/compare_reports.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdacite\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dict\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Correlation, Settings\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseDescription\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mydata_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malerts\u001b[39;00m \u001b[39mimport\u001b[39;00m Alert\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/ydata_profiling/config.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Union\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, BaseSettings, Field, PrivateAttr\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_dictionaries\u001b[39m(dict1: \u001b[39mdict\u001b[39m, dict2: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     11\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m    :return: Merged dictionary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pydantic/__init__.py:206\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    204\u001b[0m dynamic_attr \u001b[39m=\u001b[39m _dynamic_imports\u001b[39m.\u001b[39mget(attr_name)\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m dynamic_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattr_migration(attr_name)\n\u001b[1;32m    208\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n\u001b[1;32m    210\u001b[0m module \u001b[39m=\u001b[39m import_module(_dynamic_imports[attr_name], package\u001b[39m=\u001b[39m__package__)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pydantic/_migration.py:279\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m import_string(DEPRECATED_MOVED_IN_V2[import_path])\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpydantic:BaseSettings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSee https://docs.pydantic.dev/\u001b[39m\u001b[39m{\u001b[39;00mVERSION\u001b[39m}\u001b[39;00m\u001b[39m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfor more details.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    285\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mimport_path\u001b[39m}\u001b[39;00m\u001b[39m` has been removed in V2.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.0.2/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.0.2/u/import-error"
          ]
        }
      ],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Correlation study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can use `OrdinalEncoder` to transform categorical variables into integer values, this is so they can be correlated to `Attrition_Flag`. Firstly, determining the categeorical variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "cols = df.columns[df.dtypes=='object'].to_list()\n",
        "df_oe = df.copy()\n",
        "\n",
        "for col in cols:\n",
        "    print(col)\n",
        "    print(df[col].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some of these variables, such as `Education_level`, have a ranking. This ordering will be assigned using preset lists for `OrdinalEncoder`'s `categories` argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "cat_list = [['M', 'F'],\n",
        "            ['Uneducated', 'High School', 'College',\n",
        "            'Unknown', 'Graduate', 'Post-Graduate',\n",
        "            'Doctorate'],\n",
        "            ['Single', 'Unknown', 'Divorced', 'Married'],\n",
        "            ['Less than $40K', '$40K - $60K', 'Unknown',\n",
        "            '$60K - $80K', '$80K - $120K', '$120K +'],\n",
        "            ['Blue', 'Silver', 'Gold', 'Platinum']]\n",
        "\n",
        "encoder = OrdinalEncoder(categories=cat_list)\n",
        "encoded_array = encoder.fit_transform(df[cols])\n",
        "\n",
        "for i, col in enumerate(cols):\n",
        "    df_oe[col] = encoded_array[:,i]\n",
        "\n",
        "df_oe.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `.corr()` for both `spearman` and `pearson` to investigate the top 10 correlations for each method by returning a dataframe ordered in descending order of correlation coefficient, with the correlation between target and itself excluded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_oe.corr(method='spearman')['Attrition_Flag'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same for `pearson`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_oe.corr(method='pearson')['Attrition_Flag'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that redundant variables that were included by the dataset uploader, as well as variables related to customer account usage are the most correlated variables. As such, we drop these to only include variables available for a prospect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_oe_dropped = df_oe.drop(['Unnamed: 0',\n",
        "                            'Months_on_book', \n",
        "                            'Months_Inactive_12_mon',\n",
        "                            'Contacts_Count_12_mon',\n",
        "                            'Total_Revolving_Bal',\n",
        "                            'Avg_Open_To_Buy',\n",
        "                            'Total_Amt_Chng_Q4_Q1',\n",
        "                            'Total_Trans_Amt',\n",
        "                            'Total_Trans_Ct',\n",
        "                            'Total_Ct_Chng_Q4_Q1',\n",
        "                            'Avg_Utilization_Ratio',\n",
        "                            'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
        "                            'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)\n",
        "\n",
        "df_oe_dropped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now repeat the correlation methods for the dataset with the usage and redundant variables dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_oe_dropped.corr(method='spearman')['Attrition_Flag'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_oe_dropped.corr(method='pearson')['Attrition_Flag'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that most variables that would be available for a prospect have very weak correlation to attrition, with only `Total_Relationship_Count` having any appreciably high correlation at all. We will consider the top 5 correlated variables presented here and study the distribution of them within attritioned customers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 5\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore we will study the following variables. We will investigate if:\n",
        "\n",
        "* An attritioned customer typically has a lower credit limit\n",
        "* An attritioned customer typically has more dependents\n",
        "* An attritioned customer tends to be female\n",
        "* An attritioned customer tends to single\n",
        "* An attritioned customer tends to have less existing relationships with the bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['Credit_Limit', 'Dependent_count', 'Gender', 'Marital_Status', 'Total_Relationship_Count']\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA on selected variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df.filter(vars_to_study + ['Attrition_Flag'])\n",
        "df_eda.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables Distibution by Attrition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the distributions (numerical and categorical) coloured by attrition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "\n",
        "def plot_categorical(df, col, target_var):\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.countplot(data=df, x=col, hue=target_var, order=df[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_numerical(df, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=df, x=col, hue=target_var, kde=True, element=\"step\")\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "target_var = 'Attrition_Flag'\n",
        "for col in vars_to_study:\n",
        "    if df_eda[col].dtype == 'object':\n",
        "        plot_categorical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        plot_numerical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parellel Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create separate DataFrame to transform `Credit_Limit` from a numerical variable into a binned categorical variable for visualizing on a `parallel_categories()` plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import numpy as np\n",
        "cred_lim_map = [-np.Inf, 7000, 14000, 21000, 28000, np.Inf]\n",
        "disc = ArbitraryDiscretiser(binning_dict={'Credit_Limit': cred_lim_map})\n",
        "df_parallel = disc.fit_transform(df_eda)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disc.binner_dict_['Credit_Limit']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create map to replace `Credit_Limit` with more informative levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = len(cred_lim_map) - 1\n",
        "classes_ranges = disc.binner_dict_['Credit_Limit'][1:-1]\n",
        "\n",
        "labels_map = {}\n",
        "for n in range(0, n_classes):\n",
        "    if n == 0:\n",
        "        labels_map[n] = f\"<{int(classes_ranges[0]/1000)}k\"\n",
        "    elif n == n_classes-1:\n",
        "        labels_map[n] = f\"+{int(classes_ranges[-1]/1000)}k\"\n",
        "    else:\n",
        "        labels_map[n] = f\"{int(classes_ranges[n-1]/1000)}k to {int(classes_ranges[n]/1000)}k\"\n",
        "\n",
        "labels_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace using `.replace()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_parallel['Credit_Limit'] = df_parallel['Credit_Limit'].replace(labels_map)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates multi-dimensional categorical data plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.parallel_categories(df_parallel, color=\"Attrition_Flag\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlations and plot interpretations converge to a certain extent, e.g. in the `Marital_Status` plot it can be observed that single customers attrition at a higher rate than married customers, on the `Total_Relationship_Count` plot customers with less relationships attrition at a higher rate than customers with more relationships. However, these correlations are shown to be very weak. The bank would be advised to collect different data that might better predict customer's tendency to attrtion. \n",
        "\n",
        "* An attritioned customer typically has a lower credit limit\n",
        "* An attritioned customer typically has more dependents\n",
        "* An attritioned customer tends to be female\n",
        "* An attritioned customer tends to single\n",
        "* An attritioned customer tends to have less existing relationships with the bank"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
